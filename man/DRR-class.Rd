% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/drr.R
\docType{class}
\name{DRR-class}
\alias{DRR}
\alias{DRR-class}
\title{Dimensionality Reduction via Regression}
\format{Parameters are a list with the following elements:
\describe{
  \item{ndim}{The number of dimensions}
  \item{lambda}{The regularization parameter for the ridge
  regression.}
  \item{kernel}{The kernel to use for KRR, defaults to
  \code{"rbfdot"}.}
  \item{kernel.pars}{A list with kernel parameters, elements depend
  on the kernel used, \code{"rbfdot"} uses \code{"sigma"}.}
  \item{pca}{logical, should an initial pca step be performed,
  defaults to \code{TRUE}.}
  \item{pca.center}{logical, should the data be centered before the
  pca step. Defaults to \code{TRUE}.}
  \item{pca.scale}{logical, should the data be scaled before the
  pca ste. Defaults to \code{FALSE}.}
  \item{fastcv}{logical, should \code{\link[CVST]{fastCV}} from the
  CVST package be used instead of normal cross-validation.}
  \item{fastcv.test}{If \code{fastcv = TRUE}, separate test data set for fastcv.}
  \item{cv.folds}{if \code{fastcv = FALSE}, specifies the number of
  folds for crossvalidation.}
  \item{fastkrr.nblocks}{integer, higher values sacrifice numerical
  accuracy for speed and less memory, see below for details.}
  \item{verbose}{logical, should the cross-validation results be
  printed out.}
}}
\usage{
## see examples and \link{embed}.
drr@fun(data, pars, keep.org.data = TRUE)
embed(data, "drr", ...)
}
\description{
Instance of \code{\link{dimRedMethod}} for Dimensionality Reduction
via Regression (DRR).
}
\details{
Wraps around \code{\link[DRR]{drr}}, see there for details. DRR is
a nonlinear extension of principal components analysis using Kernel
Ridge Regression (KRR, details see \code{\link[CVST]{constructKRRLearner}}
and \code{\link[DRR]{constructFastKRRLearner}}). Non-linear
regression is used to explain more variance than PCA. DRR provides
an out-of-sample extension and a backward projection.

The most expensive computations are matrix inversions therefore the
implementation profits a lot from a multithreaded BLAS library.
The best parameters for each KRR are determined by cross-validaton
over all parameter combinations of \code{lambda} and
\code{kernel.pars}, using less parameter values will speed up
computation time. Calculation of KRR can be accelerated by
increasing \code{fastkrr.nblocks}, it should be smaller than
n^{1/3} up to sacrificing some accuracy, for details see
\code{\link[DRR]{constructFastKRRLearner}}. Another way to speed up
is to use \code{pars$fastcv = TRUE} which might provide a more
efficient way to search the parameter space but may also miss the
global maximum, I have not ran tests on the accuracy of this method.
}
\examples{
dat <- loadDataSet("variable Noise Helix", n = 200)[sample(200)]
drr <- DRR()
pars <- drr@stdpars
pars$ndim <- 3
emb <- drr@fun(dat, pars)

plot(dat, type = "3vars")
plot(emb, type = "2vars")
plot(emb@inverse(emb@data@data[,1,drop = FALSE]), type = "3vars")



}
\references{
Laparra, V., Malo, J., Camps-Valls, G.,
    2015. Dimensionality Reduction via Regression in Hyperspectral
    Imagery. IEEE Journal of Selected Topics in Signal Processing
    9, 1026-1036. doi:10.1109/JSTSP.2015.2417833
}

